---
format: html
editor: 
  markdown: 
    wrap: 80
---

# Preprocesado

A veces tenemos que ajustar nuestros datos de entrada para que encajen con lo
que espera el algoritmo

## Escalado de caracterísicas

Muchas veces los datos de diferentes orígenes, columnas, dimensiones, vienen en
distintas escalas.

Muy importante para:

-   Algoritmos que utilicen medidas de distancia: kmeans, knearest neighbors

Puede ser interesante para:

-   Regresiones/Redes neuronales para acelerar la convergencia

No es necesario para:

-   Algoritmos basados en árboles

# ¿Por qué es necesario?

Cuando estamos trabajando con dataframes con múltiples variables, cada una
generalmente se mueve en un rango diferente.

Ejemplo a veces tenemos datos en diferents métricas: distancia, superficie,
temperatura energía, etc.. o aunque se trata de las mismas métricas se mueven en
rangos diferentes.

Para que los datos de las diferentes dimensiones sean comparables recurrimos al
reescalado de dichas variables.

### Estandarización

El resultado consiste en dejar nuestros datos con media 0 y varianza 1: $$
X_n=\frac{X-\mu}{\sigma}
$$

### Normalización

Las dos **normalizaciones más comunes** son:

Podemos maximizar para dejar todos nuestros datos en el rango \[0,1\]: $$
X_n=\frac{X- min\{X\} }{max\{X\}-min\{X\}}
$$ A veces existen variaciones de esta normalización. El máximo y el mínimo
puede ser peligroso si tenemos outliers, es posible que primero tengamos que
eliminarlos. También podemos utilizar percentiles.

Existen infinidad de formas diferentes de normalizar los datos.

#### Ejemplo proteinas

Dataset extraido de:
https://archive.ics.uci.edu/ml/datasets/Mice+Protein+Expression

El conjunto de datos consiste en los niveles de expresión de 77 proteínas /
modificaciones de proteínas que produjeron señales detectables en la fracción
nuclear del cortex. Hay 38 ratones de control y 34 ratones trisómicos (síndrome
de Down), para un total de 72 ratones. En los experimentos, se registraron 15
mediciones de cada proteína por muestra / ratón. Por lo tanto, para ratones de
control, hay 38x15, o 570 mediciones, y para ratones trisómicos, hay 34x15, o
510 mediciones. El conjunto de datos contiene un total de 1080 mediciones por
proteína. Cada medida puede considerarse como una muestra / ratón independiente.

Las ocho clases de ratones se describen en función de características como el
genotipo, el comportamiento y el tratamiento. Según el genotipo, los ratones
pueden ser de control o trisómicos. Según el comportamiento, algunos ratones han
sido estimulados para aprender y otros no, para evaluar el efecto del
medicamento memantina en la recuperación de la capacidad de aprender en ratones
trisómicos, algunos ratones han sido inyectado con la droga y otros no.

Clases \* c-CS-s: ratones de control, estimulados para aprender, inyectados con
solución salina (9 ratones) \* c-CS-m: ratones de control, estimulados para
aprender, inyectados con memantina (10 ratones) \* c-SC-s: ratones de control,
no estimulados para aprender, inyectados con solución salina (9 ratones) \*
c-SC-m: ratones de control, no estimulados para aprender, inyectados con
memantina (10 ratones)

-   t-CS-s: ratones con trisomía, estimulados para aprender, inyectados con
    solución salina (7 ratones)
-   t-CS-m: ratones con trisomía, estimulados para aprender, inyectados con
    memantina (9 ratones)
-   t-SC-s: ratones con trisomía, no estimulados para aprender, inyectados con
    solución salina (9 ratones)
-   t-SC-m: ratones con trisomía, no estimulados para aprender, inyectados con
    memantina (9 ratones)

Los niveles absolutos de expresión de un gen no son comprarables con los de
otro. Para hacerlo comparables es necesario que todos los niveles de expresión
se muevan en los mismos rangos.

![](https://upload.wikimedia.org/wikipedia/commons/1/14/Extended_Central_Dogma_with_Enzymes_gl.png)

```{r}
mouse<-read.csv("data/Data_Cortex_Nuclear.csv")
#mouse_data<-mouse[,c(2:78,79)]
mouse_data<-mouse[,c(2:78,82)]
head(mouse_data)
```

Comprobamos que los margenes en los que se mueve el nivel de expresión de cada
gen es muy diferente y los hace dificilmente comparables.

```{r}
summary(mouse_data)
```

```{r}
library(ggplot2)
options(repr.plot.height=4,repr.plot.width=6,repr.plot.res = 200)

ggplot(mouse_data,aes(x=DYRK1A_N,y=pCAMKII_N,color=class))+geom_point(size=0.1)+ coord_fixed() 
```

Tras aplicar una normalización podemos comparar su nivel de expresión con mayor
claridad y ver que influye en cada clase:

```{r}
library(pracma)
mouse_data_noclass<-mouse_data
mouse_data_noclass$class<-NULL
gem_m<-colMeans(mouse_data_noclass,na.rm = T)
gem_sd<-sapply(mouse_data_noclass, sd,na.rm=T)
mnCols<-repmat(gem_m,n = nrow(mouse_data_noclass),m=1)
sdCols<-repmat(gem_sd,n = nrow(mouse_data_noclass),m=1)
mouse_data_norm<-(mouse_data_noclass-mnCols)/sdCols
mouse_data_norm$class<-mouse_data$class
```

```{r}
# Otra forma de hacer lo mismo utilizando funciones de R
mouse_data_noclass<-mouse_data
mouse_data_noclass$class<-NULL

mouse_data_norm<-as.data.frame(apply(mouse_data_noclass,2,scale,center=TRUE,scale=TRUE))
mouse_data_norm$class<-mouse_data$class
```

```{r}
summary(mouse_data_norm)
```

```{r}
ggplot(mouse_data_norm,aes(x=DYRK1A_N,y=pCAMKII_N,color=class))+geom_point(size=0.1)+ coord_fixed() 
```

### Ejemplo

Recuperemos el ejemplo de la predicción de la potencia de generación de una
central de ciclo combinado

El conjunto de datos contiene 9568 puntos de datos recopilados de una Central de
Ciclo Combinado durante 6 años (2006-2011), cuando la planta de energía se puso
a funcionar con carga completa. Las características consisten en variables
ambientales promedio por hora, Temperatura (T), Presión ambiente (AP), Humedad
relativa (HR) y Vacío de escape (V) para predecir la producción neta de energía
eléctrica por hora (EP) de la planta.

Las características consisten en variables ambientales promedio por hora -
Temperatura (AT) en el rango de 1.81 ° C y 37.11 ° C, - Presión ambiental (AP)
en el rango de 992.89-1033.30 milibares, - Humedad relativa (HR) en el rango de
25.56% a 100.16% - Vacío de escape (V) en el rango de 25.36-81.56 cm Hg -
Producción neta de energía eléctrica por hora (EP) 420.26-495.76 MW

Los promedios se toman de varios sensores ubicados alrededor de la planta que
registran las variables ambientales cada segundo. Las variables se dan sin
normalización.

https://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant

Cada columna, cada variable viene uno un rango de funcionamiento diferente y es
dificil comparalro entre ellos.

```{r}
powerplant<-read.csv("data/powerplant.csv")
```

```{r}
idx<-sample(1:nrow(powerplant),nrow(powerplant)*0.7)
powerplant.train<-powerplant[idx,]
powerplant.test <-powerplant[-idx,]
```

```{r}
library(GGally)
options(repr.plot.height=4,repr.plot.width=6)
ggpairs(powerplant.train, 
        lower = list(continuous = wrap("density", alpha = 0.8,size=0.2,color='blue'))
       #lower = list(continuous = wrap("points", alpha = 0.3,size=0.1,color='blue'))
       )
```

```{r}
set.seed(1234)

model_powerplant<-lm(PE~.,data=powerplant.train)
summary(model_powerplant)
```

```{r}
powerplant.test$pe_est<-predict(model_powerplant,powerplant.test)
paste("Error cuadrático medio",sqrt(mean((powerplant.test$PE-powerplant.test$pe_est)^2)))
```

Podemos escalar nuestros datos para que todos esten en el mismo rango.

Habría que hacerlo solo con los elementos de train, porque se supone que los
datos de test no los hemos visto nunca.

```{r}
#gem_m<-colMeans(powerplant.train)
#gem_sd<-sapply(powerplant.train, sd,na.rm=T)
#mnCols<-repmat(gem_m,n = nrow(powerplant.train),m=1)
#sdCols<-repmat(gem_sd,n = nrow(powerplant.train),m=1)

#powerplant_norm.train<- (powerplant.train-mnCols)/sdCols
#preProcValues$mean
#preProcValues$std
```

```{r}
library(dplyr)
preProcValues <- powerplant.train %>% select(-PE) %>% caret::preProcess( method = c("center", "scale"))

powerplant_norm.train<-predict(preProcValues, powerplant.train)
summary(powerplant_norm.train)
```

```{r}
ggpairs(powerplant_norm.train, 
        lower = list(continuous = wrap("density", alpha = 0.8,size=0.2,color='blue'))
       )
```

```{r}
model_powerplant_norm<-lm(PE~.,data=powerplant_norm.train)
summary(model_powerplant_norm)
```

```{r}
powerplant_norm.train$pe_est<-predict(model_powerplant_norm,powerplant_norm.train)
paste("Error cuadrático medio",sqrt(mean((powerplant_norm.train$PE-powerplant_norm.train$pe_est)^2)))
```

```{r}
powerplant_norm.test<-predict(preProcValues, powerplant.test)

powerplant_norm.test$pe_est<-predict(model_powerplant_norm,powerplant_norm.test)
paste("Error cuadrático medio",sqrt(mean((powerplant_norm.test$PE-powerplant_norm.test$pe_est)^2)))
```

```{r}
library(microbenchmark)
set.seed(50)
mb<-microbenchmark(lm(PE~.,data=powerplant.train),times=1000)
print(mb)
set.seed(50)
mb<-microbenchmark(lm(PE~.,data=powerplant_norm.train),times=1000)
print(mb)
```

```{r}
?microbenchmark
```

```{r}
set.seed(50)
mb<-microbenchmark(glm(PE~.,data=powerplant.train),times=1000)
print(mb)
set.seed(50)
mb<-microbenchmark(glm(PE~.,data=powerplant_norm.train),times=1000)
print(mb)
```

## Transformación de variable

A veces se transforma la variable para conseguir que su distribución siga una
normal y/o varianza constante. Una de las tecnicas consiste en buscar el
parámetro $\lambda$ que maximiza el estimador de máxima verosimilitud:

$$
f(y,\lambda)\left\{\begin{matrix}
\frac{y^\lambda-1}{\lambda} ~~ si~~ \lambda \neq 0\\ 
log(y) ~~ si~~ \lambda = 0\\ 
\end{matrix}\right.
$$

Esta transformaxión se suele conocer como la transformación box-cox. Funciona
para valores estrictamente positivos.

```{r}
library(MASS)
bx<-boxcox(model_powerplant,lambda=seq(-5,1,length.out = 100))
```

```{r}
l<-bx$x[which.max(bx$y)]
my_transform<-function(y,l){
    (y^l-1)/l
}
```

```{r}
powerplant_transformed.train<-powerplant.train
powerplant_transformed.train$PE_tr<-my_transform(powerplant.train$PE,l)
model_powerplant_tr<-lm(PE_tr~AT+V+AP+RH,data=powerplant_transformed.train)
```

```{r}
par(mfrow = c(1,2))
qqnorm(y=model_powerplant$residuals,cex=0.1)
qqline(y=model_powerplant$residuals,cex=0.1,col="red")

qqnorm(y=model_powerplant_tr$residuals,cex=0.1)
qqline(y=model_powerplant_tr$residuals,cex=0.1,col="red")
```

### Ejemplo hormigón

```{r}
concrete<-read.csv("data/Concrete_Data.csv",
                   col.names=c("cemento","escoria","cenizas","agua","plastificante","aggrueso","agfino","edad","resistencia"))
head(concrete)
```

```{r}
set.seed(123)
idx<-sample(1:nrow(concrete),nrow(concrete)*0.7)
concrete_train.df<-concrete[idx,]
concrete_test.df<-concrete[-idx,]
```

```{r}
#model_concrete<-lm(resistencia~cemento+escoria+cenizas+agua+plastificante+aggrueso+agfino+edad,concrete_train.df)
model_concrete<-lm(resistencia~cemento+escoria+cenizas+agua+plastificante+aggrueso+agfino+edad,concrete_train.df)
summary(model_concrete)
```

```{r}
bx<-MASS::boxcox(model_concrete,lambda=seq(-1,2,length.out = 100))
```

```{r}
l<-bx$x[which.max(bx$y)]
my_transform<-function(y,l){
    (y^l-1)/l
}
my_inv_transform<-function(x,l){
    (x*l+1)^(1/l)
}
l
```

```{r}
concrete_transformed.train<-concrete_train.df
concrete_transformed.train$resistencia_tr<-my_transform(concrete_train.df$resistencia,l)


model_concrete_tr<-lm(resistencia_tr~cemento+escoria+cenizas+agua+plastificante+aggrueso+agfino+edad,
                      concrete_transformed.train)
summary(model_concrete_tr)
```

```{r}
par(mfrow = c(1,2))
qqnorm(y=concrete_transformed.train$resistencia,cex=0.1)
qqline(y=concrete_transformed.train$resistencia,cex=0.1,col="red")

qqnorm(y=concrete_transformed.train$resistencia_tr,cex=0.1)
qqline(y=concrete_transformed.train$resistencia_tr,cex=0.1,col="red")
```

```{r}
par(mfrow = c(1,2))
qqnorm(y=model_concrete$residuals,cex=0.1)
qqline(y=model_concrete$residuals,cex=0.1,col="red")

qqnorm(y=model_concrete_tr$residuals,cex=0.1)
qqline(y=model_concrete_tr$residuals,cex=0.1,col="red")
```

```{r}
pred_train<-concrete_transformed.train[,c("resistencia_tr")]
```

```{r}
caret::postResample(concrete_test.df$resistencia,
                    predict(model_concrete,concrete_test.df))
plot(concrete_test.df$resistencia,
     concrete_test.df$resistencia-predict(model_concrete_tr,concrete_test.df))
```

```{r}
concrete_transformed.test<-concrete_test.df
concrete_transformed.test$resistencia_tr<-my_transform(concrete_test.df$resistencia,l)
concrete_transformed.test$pred_tr<-predict(model_concrete_tr,concrete_transformed.test)
concrete_transformed.test$pred<-my_inv_transform(concrete_transformed.test$pred_tr,l)

with(concrete_transformed.test,{
        
    print(caret::postResample(resistencia_tr,pred_tr))
    print(caret::postResample(resistencia,pred))
    plot(resistencia_tr, resistencia_tr-pred_tr)
    plot(resistencia, resistencia-pred)
    })
```

```{r}
model_concrete_poli<-lm(
    resistencia~poly(cemento,2)+poly(escoria,2)+poly(cenizas,2)+poly(agua,2)+
    poly(plastificante,2)+poly(aggrueso,2)+poly(agfino,2)+poly(edad,2),
                      concrete_train.df)
caret::postResample(concrete_test.df$resistencia,predict(model_concrete_poli,concrete_test.df))
plot(concrete_test.df$resistencia,
     concrete_test.df$resistencia-predict(model_concrete_poli,concrete_test.df))
```

```{r}
model_concrete_poli_tr<-lm(
    resistencia_tr~poly(cemento,2)+poly(escoria,2)+poly(cenizas,2)+poly(agua,2)+
    poly(plastificante,2)+poly(aggrueso,2)+poly(agfino,2)+poly(edad,2),
                      concrete_transformed.train)


concrete_transformed.test<-concrete_test.df
concrete_transformed.test$resistencia_tr<-my_transform(concrete_test.df$resistencia,l)
concrete_transformed.test$pred_tr<-predict(model_concrete_poli_tr,concrete_transformed.test)
concrete_transformed.test$pred<-my_inv_transform(concrete_transformed.test$pred_tr,l)

with(concrete_transformed.test,{
        
    print(caret::postResample(resistencia_tr,pred_tr))
    print(caret::postResample(resistencia,pred))
    plot(resistencia_tr, resistencia_tr-pred_tr)
    plot(resistencia_tr, resistencia-pred)
    })
```

```{r}
model_concrete_poli<-lm(
    resistencia~poly(cemento,2)+poly(escoria,2)+poly(cenizas,2)+poly(agua,2)+
    poly(plastificante,2)+poly(aggrueso,2)+poly(agfino,2)+poly(edad,2),
                      concrete_train.df)

concrete_test.df$pred<-predict(model_concrete_poli,concrete_test.df)

with(concrete_test.df,{            
    print(caret::postResample(resistencia,pred))    
    plot(resistencia, resistencia-pred)
    })
```

## Valores no disponibles / Missing Values

Son valores para los cuales no tenemos ninguna medida, se representan con un NA.

Pertenecen a valores perdidos que no se han podido recuperar, errores de medida,
perdidas de datos, etc..

En R los detectamos con:

is.na(x) y podemos reemplazar su valor con la media, moda, mediana, etc...

o simplemente eliminarlos: na.omit(x)

Si estamos trabajando con series temporales es posible que queramos hacer una
interpolación de los valores perdidos:

zoo::na.approx(x)

```{r}
data<-c(1,3,NA,6)
data
```

```{r}
is.na(data)
```

```{r}
mouse<-read.csv("data/Data_Cortex_Nuclear.csv")
#mouse_data<-mouse[,c(2:78,79)]
summary(mouse)
```

```{r}
sapply(mouse,function(x) sum(is.na(x)))
```

```{r}
which(is.na(mouse$pMTOR_N))
```

```{r}
mouse_no_na<-na.omit(mouse)
nrow(mouse_no_na)
```

```{r}
#Los índices que NO ha eliminado son:
length(na.action(na.omit(mouse)))
```

```{r}
str(na.action(na.omit(mouse)))
```

```{r}
nrow(mouse)
nrow(na.omit(mouse))
nrow(mouse)-nrow(na.omit(mouse))
```

```{r}
na.action(na.omit(mouse))
```

```{r}
head(na.omit(mouse))
```

Podemos reemplazar su valor por la media de esa columna.

Vamos a ver tres formas diferentes de hacer lo mismo.

```{r}
mouse_data<-mouse[,2:77]
```

```{r}
for (i in 1:ncol(mouse_data)){
    mouse_data[,i]<-replace(mouse_data[,i],is.na(mouse_data[,i]),mean(mouse_data[,i],na.rm=T))
}
```

```{r}
mouse_data=as.data.frame(sapply(mouse_data,function(mcol) replace(mcol, is.na(mcol), mean(mcol, na.rm = TRUE))))
```

```{r}
library(zoo)
mouse_data=na.aggregate(mouse_data,FUN=mean)
```

## Outliers

Un outlier es una obervación que se encuentra a una distancia **anormal** de
otros valores de la muestra.

La definición está abierta, todo depende de que datos se quieran descartar
(reemplazar por NA).

Los podemos identificar mediate diagramas de dispersión o diagramas de cajas.

Una forma podría ser considerar outlier todo lo que esté fuera del rango: $$
{\big [}Q_{1}-k(Q_{3}-Q_{1}),Q_{3}+k(Q_{3}-Q_{1}){\big ]}
$$ Donde un valor típico de $k$ es 1.5

Lo podemos reemplazar por un valor extremo, por la media, moda, etc...o
descartarlo al igual que los NA
